{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** A type of Learning where the target is given and you wish to find the function that maximized the likelihood of predicting the target **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification** : When your targets value is a subset of integers up to isomorphism.  example:   [1,3,2,1,4,2] or ['happy','sad','calm']\n",
    "\n",
    "**Regression** : when your target is a subset of reals up to isomorphism.    example: [1.3,2.52,1,2.0,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalization, Overfitting, Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Here is an Example to understand Overfitting **\n",
    "Imagine all you know about human behavior was how one specific person in the world behaved.  You study every aspect and mimic this persons behavior to the best of your ability.  Now you go out to the world and you have to predict how I or anyone else will behave in a give situation.  How do you think you will do?  \n",
    "\n",
    "**Probably really bad** since you have overtrained and over studied the person that you were with you will look for only the targets behavior as the ground truth. This is over fitting.  When you look at every detail and then try to model it in real life.  You would have been better off to get a general idea of what that person does in certain situation rather than trying to copy everything.  \n",
    "\n",
    "**Now underfitting**\n",
    "imagine again you have seen one person in your life and you decide to only mimic this persons every action by it being good or bad.  our actions have a lot more complexity than just being good or bad and therefore trying to predict actions will again fall short because we lack complexity.  \n",
    "\n",
    "\n",
    "**Sweet Spot**\n",
    "We want to be in the sweet spot where the complexity is just enough to captrure the model of interest but not too much to overfit and give bad predictions.  \n",
    "\n",
    "Mathematically complexity can be thought of as the degree of the function you are using to model. \n",
    "\n",
    "**How does this effect training set vs test set**\n",
    "If you can predict the training set 100% you have over fit and will generalize poorly on the test set.  if you can barely predict training set you have underfitted and will generalize poorly due to lack of information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
